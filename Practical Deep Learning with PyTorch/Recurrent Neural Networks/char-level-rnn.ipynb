{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRGQTgy0APg9-gh"
   },
   "source": [
    "# Music generation with a Character-level Recurrent Neural Network\n",
    "\n",
    "Hi, and welcome! In this lab, we will get creative and learn how to generate songs in the style of Chopin. Let's the show begin!\n",
    "\n",
    "**GPU** is recomended for this assignment. `Runtime` -> `Change runtime type` -> `GPU`\n",
    "\n",
    "**Instructions**\n",
    "- Write code in the space indicated with `### START CODE HERE ###`\n",
    "- Do not use loops (for/while) unless instructions explicitly tell you so. Parallelization in Deep Learning is key!\n",
    "- If you get stuck, ask for help in Slack or DM `@DRU Team`\n",
    "\n",
    "**You will learn**\n",
    "- How to build an image segmentation algorithm\n",
    "    - How to preprocess midi files\n",
    "    - How to build an LSTM model\n",
    "    - How to sample from a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44jUXTWh38Nn"
   },
   "source": [
    "# 0 - Set up the environment\n",
    "We recommend that you use Google Colab for this lab. However, if you are running this lab on an OS without `apt-get`, you can use [Homebrew](https://brew.sh/) on macOS (or Linux) or [Chocolatey](https://chocolatey.org/) on Windows to install `lilypond` and `fluidsynth`. In any case, those two packages are not required for completing this lab. We will use them to display sheet music and play it in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7518,
     "status": "ok",
     "timestamp": 1627405159191,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "an8k9mD738No",
    "outputId": "bf1a8858-c038-4102-8ddd-221b2f656f17"
   },
   "outputs": [],
   "source": [
    "# install music21\n",
    "!pip install music21\n",
    "\n",
    "# enables music21 to render images of musical notes\n",
    "print('installing lilypond...')\n",
    "!apt-get install lilypond > /dev/null\n",
    "\n",
    "# converts midi files to wav files into order to play them\n",
    "print('installing fluidsynth...')\n",
    "!apt-get install fluidsynth > /dev/null\n",
    "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
    "\n",
    "print('done!')\n",
    "!fluidsynth --version\n",
    "!lilypond --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1627405159191,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "XmwERHHY38Np",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:11.925861Z",
     "start_time": "2024-06-17T13:15:11.840636Z"
    }
   },
   "outputs": [],
   "source": [
    "def play(music):\n",
    "    \"\"\"plays music in Jupyter\"\"\"\n",
    "    music.write('midi', fp='temp.mid')\n",
    "    !fluidsynth -ni font.sf2 temp.mid -F temp.wav -r 16000 > /dev/null\n",
    "    display(Audio('temp.wav'))\n",
    "\n",
    "\n",
    "def show(music):\n",
    "    \"\"\"shows music sheet\"\"\"\n",
    "    display(Image(str(music.write('lily.png'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgmrR0k938Nq"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141140,
     "status": "ok",
     "timestamp": 1627405300325,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "GYEvMrno38Nq",
    "outputId": "74c7bdfc-b62f-4d48-da66-e7f38b8cadfd"
   },
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "\n",
    "wget.download('https://dru.fra1.digitaloceanspaces.com/DL_pytorch/static/4_recurrent_nn/char_level_rnn/template.zip')\n",
    "!unzip -q template.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41pH9N78Ao8p"
   },
   "source": [
    "# 1 - Import packages\n",
    "\n",
    "In this lab, we will use [music21](https://web.mit.edu/music21/) library, for parsing and creating `.midi` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1223,
     "status": "ok",
     "timestamp": 1627405301543,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "IK8erE24ktbU",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:15.571119Z",
     "start_time": "2024-06-17T13:15:15.495220Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import os, shutil\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from music21 import converter, instrument, stream, note, chord\n",
    "from IPython.display import Image, Audio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOy4hSMFh-X2"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1627405301544,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "wBhIdsvHh8Qr",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:17.778847Z",
     "start_time": "2024-06-17T13:15:17.749679Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION_FIELD[cls] Config\n",
    "\n",
    "class Config:\n",
    "    # data\n",
    "    dataroot = './Chopin'\n",
    "    # model\n",
    "    vocab_size = 284\n",
    "    seq_len = 64\n",
    "    num_layers = 3\n",
    "    hidden_size = 512\n",
    "    embedding_size = 512\n",
    "    dropout = 0.25\n",
    "    # training \n",
    "    seed = 21\n",
    "    batch_size = 8\n",
    "    learning_rate = 0.001\n",
    "    epochs = 500\n",
    "    save_every = 50\n",
    "    clip = 5\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627405301544,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "4FuDf_X-38OA",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:18.875924Z",
     "start_time": "2024-06-17T13:15:18.831963Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYN7oWm77KRS"
   },
   "source": [
    "# 2 - Data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owGsy41Za6uZ"
   },
   "source": [
    "## Preprocess Midi Files\n",
    "Here we will define a function `parse_midi` to convert a midi file to a list of notes and chords. Next, we will run this function over a dataset of 8 Chopin works taken from [Classical Music Midi dataset](https://www.kaggle.com/soumikrakshit/classical-music-midi) from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1627405301545,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "pMBhfGzHbBKo",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:21.299943Z",
     "start_time": "2024-06-17T13:15:21.279307Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_midi(file):\n",
    "    note_list = []\n",
    "    music = converter.parse(file)\n",
    "    # Handle cases for multi-instruments\n",
    "    try:\n",
    "        parts = instrument.partitionByInstrument(file)\n",
    "        notes = parts.parts[0].recurse()\n",
    "    except:\n",
    "        notes = music.flatten().notes\n",
    "\n",
    "    # Handle chords\n",
    "    for singleNote in notes:\n",
    "        if isinstance(singleNote, chord.Chord):\n",
    "            note_list.append('.'.join(str(norm) for norm in singleNote.normalOrder))\n",
    "        elif isinstance(singleNote, note.Note):\n",
    "            note_list.append(str(singleNote.pitch))\n",
    "    return note_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1841,
     "status": "ok",
     "timestamp": 1627405303379,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "hdJeZH5m38OB",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:24.955589Z",
     "start_time": "2024-06-17T13:15:21.881440Z"
    }
   },
   "outputs": [],
   "source": [
    "songs = []\n",
    "for midi_file in os.listdir(Config.dataroot):\n",
    "    if midi_file.endswith('.mid'):\n",
    "        notes = parse_midi(os.path.join(Config.dataroot, midi_file))\n",
    "        songs.append(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ1x-E4338OB"
   },
   "source": [
    "## Understanding the data\n",
    "\n",
    "Our dataset consists of **8** songs, each has a different length (maximal length of a song is **1378**, and the minimum length is **144**). Each song is a list of notes or chords. In the example below, chords are `'5.8.0'`, `'10.3'`, while individual notes are `'C5'`, `'F2'`, `'F5'`, `'E-5'`, etc. Our **task** will be to build **many-to-many** RNN that will make predictions about the next note in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1627405303380,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "6iMiiKsPd1jv",
    "outputId": "5a067b94-9eaf-4007-b15b-6f33be53934f",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:24.970789Z",
     "start_time": "2024-06-17T13:15:24.958026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 8 songs\n",
      "Length of each song: [1576, 599, 1266, 143, 665, 1008, 1087, 878]\n",
      "First 10 tokens of a third song: ['G4', 'C5', 'C2', 'G3', 'D5', 'E-5', '0.3', 'G3', 'F5', 'G5']\n"
     ]
    }
   ],
   "source": [
    "print(f'Total of {len(songs)} songs')\n",
    "print('Length of each song:', [len(song) for song in songs])\n",
    "print('First 10 tokens of a third song:', songs[1][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S27XFhF838OC"
   },
   "source": [
    "## All notes\n",
    "\n",
    "To simplify the learning objective, we will combine all tracks into one long sequence, `all_notes`. This will allow us to train our model continuously without reinitializing the hidden state of the recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1627405303381,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "2f0LFwMP38OC",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:26.549608Z",
     "start_time": "2024-06-17T13:15:26.530292Z"
    }
   },
   "outputs": [],
   "source": [
    "all_notes = np.array([note for s in songs for note in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJK0SiV_8VWi"
   },
   "source": [
    "## Collect all unique tokens\n",
    "\n",
    "The common preprocessing step in building an RNN is to transform input tokens into numeric indices. So, let's define dictionaries that convert notes(and chords) to indices and indices to notes.\n",
    "\n",
    "**Excercise** implement `get_mappings` function that takes `all_notes` as input, and returns two mapping dictionaries `note2idx` and `idx2note`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1627405303382,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "2gPppJ098byp",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:27.462073Z",
     "start_time": "2024-06-17T13:15:27.450524Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION_FIELD[func] get_mappings\n",
    "\n",
    "def get_mappings(notes):\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    idx2note = dict(enumerate(sorted(set(notes))))\n",
    "    note2idx = {v: k for k, v in idx2note.items()}\n",
    "    ### END CODE HERE ###\n",
    "    return note2idx, idx2note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1627405303383,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "lSkFFOm038OD",
    "outputId": "ca6636b3-bc7e-4bfe-b33e-ccc6b318d569",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:28.140873Z",
     "start_time": "2024-06-17T13:15:28.128672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note to index mapping: {'10.3': 0, '5.8.0': 1, 'C#5': 2, 'C5': 3, 'E-5': 4, 'F2': 5, 'F5': 6, 'G#2': 7, 'G2': 8}\n",
      "Index to note mapping: {0: '10.3', 1: '5.8.0', 2: 'C#5', 3: 'C5', 4: 'E-5', 5: 'F2', 6: 'F5', 7: 'G#2', 8: 'G2'}\n"
     ]
    }
   ],
   "source": [
    "notes_example = np.array(['C5', 'F2', 'F5', '5.8.0', 'E-5', 'G2', 'C#5', '10.3', 'F5', 'G#2', 'C5'])\n",
    "note2idx, idx2note = get_mappings(notes_example)\n",
    "print('Note to index mapping:', note2idx)\n",
    "print('Index to note mapping:', idx2note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25RsMo8238OE"
   },
   "source": [
    "**Expected output:**\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Note to index</b></td>\n",
    "        <td>{'10.3': 0, '5.8.0': 1, 'C#5': 2, 'C5': 3, 'E-5': 4, 'F2': 5, 'F5': 6, 'G#2': 7, 'G2': 8}\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>Index to note</b></td>\n",
    "        <td>{0: '10.3', 1: '5.8.0', 2: 'C#5', 3: 'C5', 4: 'E-5', 5: 'F2', 6: 'F5', 7: 'G#2', 8: 'G2'}\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1627405303384,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "kbI4ozyS38OE",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:29.388348Z",
     "start_time": "2024-06-17T13:15:29.374556Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply idx transformation on notes\n",
    "note2idx, idx2note = get_mappings(all_notes)\n",
    "all_notes = np.array([note2idx[note] for note in all_notes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGIJ1o9V83-h"
   },
   "source": [
    "## Generate music from an array\n",
    "\n",
    "Next, we will define a function that will generate a music stream out of a NumPy array. We will use `lilypond` and `fluidsynth` to see and listen to the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1627405303386,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "afV6KhfVcKLK",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:30.378112Z",
     "start_time": "2024-06-17T13:15:30.366825Z"
    }
   },
   "outputs": [],
   "source": [
    "def array_to_music(array):\n",
    "    offset = 0\n",
    "    midiOutput = []\n",
    "    for notePat in array:\n",
    "        # It is a chord.\n",
    "        if ('.' in notePat) or notePat.isdigit():\n",
    "            # Split to notes\n",
    "            notes_in_chord = notePat.split('.')\n",
    "            notes = []\n",
    "\n",
    "            # chord as notes\n",
    "            for eachNote in notes_in_chord:\n",
    "                new_note = note.Note(int(eachNote))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "\n",
    "            # Convert to midi chord and store\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            midiOutput.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            # Convert to midi note and store\n",
    "            new_note = note.Note(notePat)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            midiOutput.append(new_note)\n",
    "        # increase offset to make sure notes do not stack\n",
    "        offset += 0.5\n",
    "    # Convert to midi stream\n",
    "    music = stream.Stream(midiOutput)\n",
    "    return music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "10rEeut7XyolREd3FaXGKlPrJJk60CJ_C"
    },
    "executionInfo": {
     "elapsed": 20256,
     "status": "ok",
     "timestamp": 1627405323626,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "ZdR2tNcr86eA",
    "outputId": "2dc6cbf1-07cf-402f-fc37-b78bbdacd092",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:15:31.352651Z",
     "start_time": "2024-06-17T13:15:31.203237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m notes \u001B[38;5;241m=\u001B[39m [idx2note[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m all_notes[:\u001B[38;5;241m250\u001B[39m]]  \u001B[38;5;66;03m# first 250 notes\u001B[39;00m\n\u001B[0;32m      2\u001B[0m music \u001B[38;5;241m=\u001B[39m array_to_music(notes)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmusic\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m show(music)\n",
      "Cell \u001B[1;32mIn[18], line 5\u001B[0m, in \u001B[0;36mplay\u001B[1;34m(music)\u001B[0m\n\u001B[0;32m      3\u001B[0m music\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmidi\u001B[39m\u001B[38;5;124m'\u001B[39m, fp\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtemp.mid\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfluidsynth -ni font.sf2 temp.mid -F temp.wav -r 16000 > /dev/null\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m display(\u001B[43mAudio\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtemp.wav\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DRU_labs\\.venv\\lib\\site-packages\\IPython\\lib\\display.py:129\u001B[0m, in \u001B[0;36mAudio.__init__\u001B[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rate \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 129\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m Audio\u001B[38;5;241m.\u001B[39m_make_wav(data, rate, normalize)\n",
      "\u001B[1;31mValueError\u001B[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "notes = [idx2note[idx] for idx in all_notes[:250]]  # first 250 notes\n",
    "music = array_to_music(notes)\n",
    "play(music)\n",
    "show(music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptc64eiWlFNe"
   },
   "source": [
    "## Create batching for our stream of notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npUFIryIluKz"
   },
   "source": [
    "Unfortunately, we cannot simply fit all `8177` notes into our model at once. This will be computationally inefficient, and our computation graph will probably be too big for the model to learn anything useful. To resolve these problems, we will do the following:\n",
    "\n",
    "* Split our notes into `batch_size` number of songs and feed them in parallel. \n",
    "* Feed only `seq_length` notes at once, and then reset our computation graph.\n",
    "\n",
    "Therefore, we want our data loader to return a tensor of shape `(batch_size, seq_length)` at every iteration. However, we don't want to reinitialize the hidden state between the batches (we will only detach it from the computation graph), so we need our data loader to generate sequential batches of notes. For example, if the **0th** sample in the first batch was `[1, 2, 3, 4, 5]` (`seq_len = 5`), we want the **0th** sample in the next batch to be `[6, 7, 8, 9, 10]`. In this case, the hidden state from the first batch will be relevant for the second batch.\n",
    "\n",
    "**Excercise:** Implement `get_dataloader` to perform batching on the given `arr` of tokens, as shown on the diagram below:\n",
    "\n",
    "<img src=\"https://dru.fra1.digitaloceanspaces.com/DL_pytorch/static/ntbk_images/batching.png\">\n",
    "\n",
    "**Hints:**\n",
    "* Discard notes if the input array is not divisible by `batch_size`\n",
    "* Output X and Y should have the shape of (batch_size, seq_length)\n",
    "* Your function should return a generator; it should `yield` the resulting batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1627405323630,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "jspWC7VK_qob",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:42:59.619470Z",
     "start_time": "2024-06-17T13:42:59.609809Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION_FIELD[func] get_dataloader\n",
    "\n",
    "def get_dataloader(arr, batch_size=Config.batch_size, seq_length=Config.seq_len):\n",
    "    \"\"\"\n",
    "    Create a generator that returns batches of size\n",
    "    (batch_size, seq_length) from arr.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (≈ 8 lines of code)\n",
    "    n_batches = arr.shape[0] // batch_size\n",
    "    # discard notes if the input array is not divisible by batch_size\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    # reshape the array\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    for n in range(0, arr.shape[1] - batch_size, seq_length):\n",
    "        # get inputs and targets\n",
    "        x = arr[:, n:n + seq_length]\n",
    "        y = arr[:, n + 1:n + seq_length + 1]\n",
    "        yield x, y\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1627405323631,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "g91ZQqec38OG",
    "outputId": "00636e68-ac3a-44a7-e1af-efabcc4fb27d",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:43:00.170031Z",
     "start_time": "2024-06-17T13:43:00.160781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs #0\n",
      "[[ 1  2  3  4]\n",
      " [10 11 12 13]\n",
      " [19 20 21 22]]\n",
      "targets #0\n",
      "[[ 2  3  4  5]\n",
      " [11 12 13 14]\n",
      " [20 21 22 23]]\n",
      "inputs #1\n",
      "[[ 5  6  7  8]\n",
      " [14 15 16 17]\n",
      " [23 24 25 26]]\n",
      "targets #1\n",
      "[[ 6  7  8  9]\n",
      " [15 16 17 18]\n",
      " [24 25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "notes = np.arange(1, 30)\n",
    "dl = get_dataloader(notes, batch_size=3, seq_length=4)\n",
    "for idx, (x, y) in enumerate(dl):\n",
    "    print(f'inputs #{idx}')\n",
    "    print(x)\n",
    "    print(f'targets #{idx}')\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GP6r8Wor38OH"
   },
   "source": [
    "**Expected output:**\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <b>input #0</b> </td>\n",
    "    <td> [[ 1  2  3  4] <br>\n",
    "          [10 11 12 13] <br>\n",
    "          [19 20 21 22]]\n",
    "    </td>\n",
    "    <td> <b>targets #0</b> </td>\n",
    "    <td> [[ 2  3  4  5] <br>\n",
    " [11 12 13 14]<br>\n",
    " [20 21 22 23]]\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td> <b>input #1</b> </td>\n",
    "    <td> [[ 5  6  7  8]<br>\n",
    " [14 15 16 17]<br>\n",
    " [23 24 25 26]]\n",
    "    </td>\n",
    "     <td> <b>targets #1</b> </td>\n",
    "    <td> [[ 6  7  8  9]<br>\n",
    " [15 16 17 18]<br>\n",
    " [24 25 26 27]]\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETngjxD7Lnfb"
   },
   "source": [
    "# 3 - Defining Model Class\n",
    "\n",
    "For this dataset, we will use a stack of several **LSTM** layers and an **Embedding** layer. \n",
    "\n",
    "<img src=\"https://dru.fra1.digitaloceanspaces.com/DL_pytorch/static/ntbk_images/stacked_lstm.png\">\n",
    "\n",
    "The **embedding** layer is used to transform an input token into a large vector that will be passed to our **LSTM** model. Basically, **embedding** simply defines a matrix of shape `(num_embeddings, embedding_dim)` as a trainable parameter, where `num_embeddings` is a number of unique notes in our dataset (`vocab_size`), and `embedding_dim` is a size of the output vector. During training, we will select a needed row of the matrix using an input index of a token. For example, if an input token is `16`, we will use `embedding[16]` to extract a vector corresponding to `16`. Next, we will pass the vector forward, calculate the loss, and backpropagate through all trainable parameters (including **embedding** layer)\n",
    "\n",
    "The **LSTM** or Long Short Term Memory network is one of the most successful RNNs. The whole idea behind LSTMs is that they can learn long-term dependencies using two hidden state vectors $C_t$ and $h_t$ instead of one (in vanilla RNN). The diagram below shows how the calculation works in LSTM:\n",
    "\n",
    "<img src=\"https://dru.fra1.digitaloceanspaces.com/DL_pytorch/static/ntbk_images/lstm_cell.png\">\n",
    "\n",
    "To stack two or more LSTM models, we will simply pass the hidden state `h_t` as inputs to the higher LSTM and use the hidden state of the highest LSTM model as our prediction.\n",
    "\n",
    "**Excercise:** Using documentation for [Embedding layer](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html), and [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) define `self.embedding` and `self.LSTM` in the `__init__` method. \n",
    "* Use `batch_first=True` for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1627405323632,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "WpE8lsaqLtuj",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:43:18.900869Z",
     "start_time": "2024-06-17T13:43:18.880004Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION_FIELD[cls] MelodyLSTM\n",
    "\n",
    "class MelodyLSTM(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size=Config.vocab_size,  # number of predicted classes (notes)\n",
    "            emb_size=Config.embedding_size,  # size of the embedding vector\n",
    "            hidden_size=Config.hidden_size,  # size of the vectors in LSTM model\n",
    "            num_layers=Config.num_layers,  # number of LSTM layers\n",
    "            drop_prob=Config.dropout  # dropout probability for training\n",
    "    ):\n",
    "        super(MelodyLSTM, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        ### START CODE HERE ### (≈10 lines of code)\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            emb_size, hidden_size, num_layers,\n",
    "            dropout=drop_prob, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x, hidden):  # x: [batch, seq_len, 1]\n",
    "\n",
    "        ### START CODE HERE ### (≈5 lines of code)\n",
    "        # Apply embedding\n",
    "        x = self.embedding(x)  # x: [batch, seq_len, emb_size]\n",
    "        # Use LSTM\n",
    "        x, hidden = self.lstm(x, hidden)  # x: [batch, seq_len, hidden_size]\n",
    "        # Use dropout\n",
    "        x = self.dropout(x)\n",
    "        # Use fully conected layer\n",
    "        x = self.fc(x)  # x: [batch, seq_len, vocab_size]            \n",
    "        # flatten x vector \n",
    "        x = x.view(-1, self.vocab_size)  # x: [batch * seq_len, vocab_size]\n",
    "        ### END CODE HERE ###\n",
    "        return x, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # get first hidden state \n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13PMQ4comFk7"
   },
   "source": [
    "# 4 - Training the model\n",
    "\n",
    "**Here, we will commit a crime!** For this problem, we will not be using a validation set, and instead, we will simply overfit the train data. This is because music generation is a very difficult task for LSTM. To achieve really good results, we would need to use transformer models or GANs that can truly generate original music. However, in our case, we will sacrifice the originality of generated sample to achieve a decent music sample. In other words, our model will **copy** a lot of fragments from Chopin but will still generate some unique samples.\n",
    "\n",
    "**Note:** a common step in training LSTM is to `clip` the gradients to prevent exploding gradient problems. To perform gradient clipping use `nn.utils.clip_grad_norm_`\n",
    "\n",
    "**Excercise:** implement the `train` function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1627405323633,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "CJnA0LmuSsu4",
    "ExecuteTime": {
     "end_time": "2024-06-17T13:44:11.878902Z",
     "start_time": "2024-06-17T13:44:11.861623Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION_FIELD[func] train\n",
    "\n",
    "def train(\n",
    "        model, optimizer, criterion, notes,\n",
    "        batch_size=Config.batch_size,\n",
    "        num_epochs=Config.epochs,\n",
    "        train_loss_min=np.inf,\n",
    "        save_every=Config.save_every,\n",
    "        clip=Config.clip,\n",
    "        device=Config.device\n",
    "):\n",
    "    losses = []\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for e in pbar:\n",
    "        train_loss = 0.0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        # initialze hidden state\n",
    "        h_0, c_0 = model.init_hidden(batch_size)\n",
    "        h_0, c_0 = h_0.to(device), c_0.to(device)\n",
    "        num_steps = 0\n",
    "        for x, y in get_dataloader(notes):\n",
    "            ### START CODE HERE ### (≈10 lines of code)\n",
    "            # pass inputs to device\n",
    "            x = torch.tensor(x).to(device)\n",
    "            y = torch.LongTensor(y).to(device)\n",
    "            # print(f'x shape: {x.shape}\\t y shape: {y.shape}')\n",
    "            # forward pass\n",
    "            out, h = model(x, (h_0, c_0))\n",
    "            # print(f'out shape: {out.shape}\\t y shape: {y.shape}')\n",
    "            loss = criterion(out, y.reshape(-1))\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if clip:\n",
    "                pass\n",
    "            optimizer.step()\n",
    "            # detach hidden state from computation graph\n",
    "            h_0, c_0 = h[0].detach(), h[1].detach()\n",
    "            ### END CODE HERE ###\n",
    "            train_loss += loss.item()\n",
    "            num_steps += 1\n",
    "        train_loss = train_loss / num_steps\n",
    "        losses.append(train_loss)\n",
    "        pbar.set_description(f'train loss: {train_loss:.5f}')\n",
    "\n",
    "        # save the model\n",
    "        if train_loss < train_loss_min:\n",
    "            torch.save(model.state_dict(), f'LSTM.pt')\n",
    "            train_loss_min = train_loss\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "7d1a9230df9c431a80c82813caa2f04e",
      "5af68b91cfac42fbbc5e0ae1f2116abf",
      "7550804b08924f55a3591decba73afc4",
      "5575d81765b743b48667741a6e8f7546",
      "26e9cccf761740d1ba90a61f592b6b17",
      "a424649d1f2b44de9f32423841df709d",
      "6ab1948dc164434b8479fdb6ae51f4dd",
      "ae401aa65f614e959e56fbc67afd5a49"
     ]
    },
    "executionInfo": {
     "elapsed": 568482,
     "status": "ok",
     "timestamp": 1627405892069,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "hcWC-7ibkU5w",
    "outputId": "3fb68cad-b76a-40d9-c22e-dc69af34fd48",
    "ExecuteTime": {
     "end_time": "2024-06-17T14:00:17.654826Z",
     "start_time": "2024-06-17T13:44:13.476518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "651deff39415480c935228332121b5b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MelodyLSTM().to(Config.device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=Config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss = train(model, optimizer, criterion, all_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_dLPb_J9HpP"
   },
   "source": [
    "**Expected Output (after 500 iterations):**\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>train loss</b>\n",
    "        </td>\n",
    "        <td>0.01062</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AymOz0DlJR15"
   },
   "source": [
    "# 5 - Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1627406102874,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "TSEME-OfzyZ7",
    "outputId": "375326fc-683a-4e43-d3e2-91da38a80e55",
    "ExecuteTime": {
     "end_time": "2024-06-17T14:00:48.945668Z",
     "start_time": "2024-06-17T14:00:48.888026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the latest model\n",
    "model.load_state_dict(torch.load('LSTM.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InwSc2Lk38OI"
   },
   "source": [
    "## Top-K sampling \n",
    "\n",
    "To generate the melody, we will use a Random Top-K Sampling method. The idea behind it is that we will feed our input sequence into the model and then do the following iterative procedure:\n",
    "1. generate outputs from neural network\n",
    "2. get top-k predictions from the output\n",
    "3. randomly choose one note using `np.random.choice`\n",
    "4. feed chosen note back into the model\n",
    "\n",
    "**Excercise:** implement `generate_sequence` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1627406124870,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "pCxqp3JFJduJ",
    "ExecuteTime": {
     "end_time": "2024-06-17T14:00:55.558678Z",
     "start_time": "2024-06-17T14:00:55.535375Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION_FIELD[func] generate_sequences\n",
    "\n",
    "def generate_sequence(model, start_sequence, note2idx, idx2note, max_length=64, topk=3, device=Config.device):\n",
    "    result = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        h, c = model.init_hidden(1)\n",
    "        h, c = h.to(device), c.to(device)\n",
    "        # feed initial sequence\n",
    "        for note in start_sequence:\n",
    "            result.append(note)\n",
    "            idx = note2idx[note]\n",
    "            idx = torch.tensor([[idx]]).to(device)\n",
    "            pred, (h, c) = model(idx, (h, c))\n",
    "            note = idx2note[pred.argmax().item()]\n",
    "        # run prediction\n",
    "        while len(result) < max_length:\n",
    "            ### START CODE HERE ### (7 lines of code)\n",
    "            # get predictions\n",
    "            idx = torch.tensor([[note2idx[note]]]).to(device)\n",
    "            pred, (h, c) = model(idx, (h, c))\n",
    "            # randomly sample from top-k predictions\n",
    "            note = idx2note[np.random.choice(pred.topk(topk).indices.cpu().numpy().flatten())]\n",
    "            ### END CODE HERE ###\n",
    "            result.append(note)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1627406192889,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "Io0PBMoTu3mv",
    "outputId": "53b2ae17-db34-4725-8aa6-0539b593b91e",
    "ExecuteTime": {
     "end_time": "2024-06-17T14:00:56.574641Z",
     "start_time": "2024-06-17T14:00:56.169473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated sequence: ['C5' '8.0' 'D5' '8.0' 'E-5' 'C5' 'F2' 'C5' '5' '4.5' 'E-5' '8.10' 'A4'\n",
      " 'C5' 'D5' '10.2' 'G#4' 'G2' 'G#4' '10.2' 'C5' 'G4' 'C#5' 'C3' 'C5' '5.8'\n",
      " 'B-4' 'B-4' 'C3' 'G#4' 'G4' 'C#3' '5.11' 'G4' '5.11' 'C5' '4.10' '8.0'\n",
      " 'C5' 'F2' 'C5' 'F5' '8.0' 'E-5' 'G2' 'G#4' '0.2' 'C5' 'B4' 'G#4' 'C5'\n",
      " 'E-5' 'G2' 'C5' '10.3' 'C#5' 'C5' '4.5.8.0' 'G5' 'F5' '3.7' 'E-4' 'B-5'\n",
      " '10.0.3' 'C5' 'C#5' 'E2' 'D5' 'C#5' 'C5' 'E2' 'G5' 'F2' 'C5' 'F5' '5.8.0'\n",
      " 'E-5' 'G2' 'G#4' '10.3' 'C5' 'G#2' 'B4' '8.0' 'E-5' 'C5' 'C#5' 'C5'\n",
      " '4.5.8.0' 'G5' 'F5' 'G2' '3.7' 'B-4' '10.0.3' 'E-5' 'C#5' 'C5' 'E-4' 'G2']\n"
     ]
    }
   ],
   "source": [
    "set_seed(Config.seed)\n",
    "notes = generate_sequence(model, ['C5'], note2idx, idx2note, max_length=100, topk=2)\n",
    "print('generated sequence:', notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AoYc0rp92f7"
   },
   "source": [
    "**Expected Output:**\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>generated sequence:</b>\n",
    "        </td>\n",
    "        <td>['C5' 'C3' 'D5' 'C5' '0.3' 'G3' '0.2' '2.7' '0.3.7' '7.0' '2.3' 'G#6' 'G5' <br>\n",
    " 'G#5' '5.8' 'C4' 'G4' 'G5' '5.8' 'C4' '4.5' '0.4' 'E-5' 'C#6' 'B-2' 'G3' <br>\n",
    " 'G5' 'E5' 'B-4' '3.7' '0.5' '8' 'F5' 'C5' '11.1' '7.10' 'D5' 'E5' 'G#4' <br>\n",
    " 'C6' '10' 'A5' '10.2' 'F#5' 'F5' 'B-2' '7.10' '3.5' 'B-5' '3.7' '8.10' <br>\n",
    " 'G5' 'B-5' '5.8' 'E-5' '0.5' '7.10' 'G4' 'B-5' '3.8' 'D5' '2.3' '7.0' <br>\n",
    " 'B-5' '5.8' 'E-5' '10.2' '7.10' 'G#4' 'E4' 'E-4' 'E-3' 'F#5' 'A5' '2.3' <br>\n",
    " '10.3' 'B-5' '3.8' 'D5' '2.3' 'F5' '10.0' 'B-5' '2.8' 'C5' '9.10.0.1' <br>\n",
    " '10.3' 'C5' '10.2' 'B-4' '2.3' '7.8' '10.2' 'B-4' 'D5' '7.8' 'G5' '7.8'\n",
    " 'D5' '0']</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9aQH_F2Qmlw"
   },
   "source": [
    "## \"Listen\" to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "output_embedded_package_id": "1SD8P6l3M3g-7ufb3tefZBH2DQ43LG5Z0"
    },
    "executionInfo": {
     "elapsed": 8714,
     "status": "ok",
     "timestamp": 1627406317796,
     "user": {
      "displayName": "Andrii Torchylo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCdcn6ViBgTXh6pJG8yqSB53JfltgvpXn4jfkZDKHoagQvvzCxABjH8hcoHdBP_eXBUJJnj6px_zNwmF5Syo7B-CnNpavmlZjWuORBaVA5oDNIqpEw7S5DlzV1alxewjkVoMHa2OCplauRVzQAGQOOYWVGB6rFTZa0yv2bpvoaOhYt9dGPoG7NmMQT1AiyEIF3-mQiiEpSLdUrR1DrYSi32uJDXM_MspgJWeAng-BtFAQiPuRcYvlL7EdWToU01DfvgNvLza8MecEYTEG6T19T1dWgqkKSxNwawlvAhKK1dRiTtOhSB2rB0Q6zyMdOmZRtHBqx1TguO4v69pcJifeFQQyzF-Byfv85rcYjfN8Ky10VO69KZaDO7oqb3Zzl42Mco23p3XZ3JdpedYm-HKzKc1DNiOCDSsiBlTL7fkZXFDJEGo2eC4qd5VMhEW57oivEPjoy8GSLWVmGrZdKuvYDQh3oijfs1DycThbMz5Z3mUPY0WUXcWXDf1bNHfIHLk1EenOSHYgSFt6q9jxVLmIKp6xaIzaahOt1WakAUEKoEN31iAbs7eaVzevZ6i-_17iUgqrbw0z5qmSZSW-eDUQidwDvYtyMliLuih943obgY0Gn0i27x4CC-vKmAgpBuQjvdYK9jmSjOmfhHSEP6QsFIaVAG2zYXACSv50hnsfPt_bgUnQyOL1oI76uSeBLtaRGidvHVaja-mC7J5DN3qYVpHz0YXthmY-GAzI8HW262lmDi7W71AqgVsf-DM6hWohh4w=s64",
      "userId": "18357331370165036741"
     },
     "user_tz": -180
    },
    "id": "CZaY7RPVHR1q",
    "outputId": "54c41030-4608-4c3c-916a-d4e643847c36",
    "ExecuteTime": {
     "end_time": "2024-06-17T14:00:59.787351Z",
     "start_time": "2024-06-17T14:00:59.580625Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[77], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m music \u001B[38;5;241m=\u001B[39m array_to_music(notes)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmusic\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m show(music)\n",
      "Cell \u001B[1;32mIn[18], line 5\u001B[0m, in \u001B[0;36mplay\u001B[1;34m(music)\u001B[0m\n\u001B[0;32m      3\u001B[0m music\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmidi\u001B[39m\u001B[38;5;124m'\u001B[39m, fp\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtemp.mid\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfluidsynth -ni font.sf2 temp.mid -F temp.wav -r 16000 > /dev/null\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m display(\u001B[43mAudio\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtemp.wav\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\DRU_labs\\.venv\\lib\\site-packages\\IPython\\lib\\display.py:129\u001B[0m, in \u001B[0;36mAudio.__init__\u001B[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rate \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 129\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m Audio\u001B[38;5;241m.\u001B[39m_make_wav(data, rate, normalize)\n",
      "\u001B[1;31mValueError\u001B[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "music = array_to_music(notes)\n",
    "play(music)\n",
    "show(music)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Char_Level_RNN.ipynb",
   "provenance": [
    {
     "file_id": "1u3Qvmg3UfAiFPScpq-QespP_MgfviA6Z",
     "timestamp": 1623682616742
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26e9cccf761740d1ba90a61f592b6b17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5575d81765b743b48667741a6e8f7546": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae401aa65f614e959e56fbc67afd5a49",
      "placeholder": "​",
      "style": "IPY_MODEL_6ab1948dc164434b8479fdb6ae51f4dd",
      "value": " 500/500 [13:17&lt;00:00,  1.59s/it]"
     }
    },
    "5af68b91cfac42fbbc5e0ae1f2116abf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab1948dc164434b8479fdb6ae51f4dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7550804b08924f55a3591decba73afc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "train loss: 0.02088: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a424649d1f2b44de9f32423841df709d",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26e9cccf761740d1ba90a61f592b6b17",
      "value": 500
     }
    },
    "7d1a9230df9c431a80c82813caa2f04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7550804b08924f55a3591decba73afc4",
       "IPY_MODEL_5575d81765b743b48667741a6e8f7546"
      ],
      "layout": "IPY_MODEL_5af68b91cfac42fbbc5e0ae1f2116abf"
     }
    },
    "a424649d1f2b44de9f32423841df709d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae401aa65f614e959e56fbc67afd5a49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
